---
title: "DA2020 - cluster analysis project (Tsimokha Dmitriy, 161)"
author: "Dmitriy Tsimokha"
date: "3/14/2020"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---


All projects will be graded according to the following criteria:

  1) data are described (name 1-3 important characteristics of your data) - 0.6 points
  2) variable choice is justified (you may want to use not all the variables) - 1 point
  3) the distance metric matches variable types - 1 point (if this is incorrect, interpretation will fail)
  4-5) you have tried a combination of k-means/PAM and agglomerative clustering - 2 points
  6) clusters have been visualized - 1 point
  7) decision on how many clusters to retain is based on tests/ dendrograms - 1 point
  8) comments on which clustering method delivers better results - 1 point
  9) the resulting clusters are described and labelled - 1.4 points
  10) the cluster solution is validated with any other methods (including but not limited to: PCA, regression, etc.) - 1 point

Original solutions are especially welcomed.

Grade descriptions:

  * 9-10 clusters are defined, described, and named the report is coherent and complete 
  * 8 clusters are defined, described, and named but 1-2 minor mistakes are allowed
  * 7 clusters are defined and described but a minor part is missing or the report contains several minor mistakes 
  * 6 clusters are defined and described but a minor part is missing or at least one serious mistake is made 
  * 5 clusters are defined but not described, the report is not coherent
  * 4 clusters are defined, analysis has flaws in logic, but it is structured (distances are calculated, clusters are identified, and results are summarised) 
  * 3 clusters are not identified, no summary provided


# Preparations

```{r}
set.seed(2020)
require(data.table); require(dplyr)
df <- fread("dataforproject2.csv", stringsAsFactors = T)
df <- df %>% select(Respondent, MainBranch, Employment, EdLevel, YearsCode)
# changing YearsCode to numeric
df <- subset(df, YearsCode != "Less than 1 year" & YearsCode != "More than 50 years")
df$YearsCode <- scale(as.numeric(df$YearsCode), center = F, scale = TRUE); df <- na.omit(df)
```


## Chosing variables

To clusterize R user meaningfully I take following variables:

  * **MainBranch**: ** 
  * **Employment**: ** 
  * **EdLevel**: ** 
  * **YearsCode**: ** 

With such variables I'm tryin to cluster respondents based on 

## Exploring data

```{r}
sapply(df[,c("MainBranch", "Employment", "EdLevel", "YearsCode")], summary)
```

As can be seen there are more respondents satisfied with their careers and jobs, also most of them think that their managers doing fine and most respondents open for a new opportunities.

# Calculating distance

```{r}
library(ISLR); library(cluster)
gower_dist <- daisy(df[,-"Respondent"], metric = "gower", type = list(logratio = 4))
summary(gower_dist); gower_mat <- as.matrix(gower_dist)
```

## Most similar cases

```{r}
df[which(gower_mat == min(gower_mat[gower_mat != min(gower_mat)]), arr.ind = TRUE)[1, ], ]
```

Looking nice, they really very similar to each other.

## Most dissimilar cases

```{r}
df[which(gower_mat == max(gower_mat[gower_mat != max(gower_mat)]), arr.ind = TRUE)[1, ], ]
```

But here we have just the same picture, that's not good at all.

## Dendrogram

```{r}
heatmap(gower_mat, symm = T,
        distfun = function(x) as.dist(x))
```


# Choosing clustering solution

## PAM

```{r}
sil_width <- c(NA)

for(i in 2:10){
  pam_fit <- pam(gower_dist,
                 diss = TRUE,
                 k = i)
  sil_width[i] <- pam_fit$silinfo$avg.width
}
```

```{r}
plot(1:10, sil_width,
     xlab = "Number of clusters", xaxt='n',
     ylab = "Silhouette Width",
     ylim = c(0,1))
axis(1, at = seq(2, 10, by = 1), las=2)
lines(1:10, sil_width)
```

I will choose **9 clusters** as optimal solution - more clusters don't gave me increase in value.

### Interpret solution

```{r}
pam_fit <- pam(gower_dist, diss = TRUE, k = 9)

df <- df %>%
  dplyr::select(-Respondent) %>%
  mutate(cluster = pam_fit$clustering)

medoids <- df[pam_fit$medoids, ]
```

With medoids and plot I can describe clusters and their dissimilarities.

# Visualizing clustering solution

## PAM solution

### Plot
```{r}
library(Rtsne); library(ggplot2)
tsne_obj <- Rtsne(gower_dist, is_distance = TRUE)

tsne_data <- tsne_obj$Y %>% # $Y is a matrix containing the new representations for the objects
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit$clustering),
         name = df$Respondent)

ggplot(aes(x = X, y = Y), data = tsne_data) +
  geom_point(aes(color = cluster))
```

### Describing by medoids

```{r}
medoids[medoids$cluster==1,]
```


## AGNES

```{r}
library(factoextra)
hfit_average <- agnes(gower_dist, method = "average")

h_avg_cut <- hcut(gower_dist, k = 8, hc_method = "ward")
fviz_cluster(h_avg_cut, iris.use, ellipse.type = "convex")
```
