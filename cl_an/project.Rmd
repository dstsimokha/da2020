---
title: "DA2020 - cluster analysis project (Tsimokha Dmitriy)"
author: "Dmitriy Tsimokha"
date: "3/14/2020"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
---

[link to the code on repo](https://github.com/dstsimokha/da2020/blob/master/cl_an/project.Rmd)

[link to the GitHub Page](http://mglotov.me/da2020/cl_an/project.html)


# Preparations

Firsly, I will transform chosen variables to more applicable forms and omit NA values for better clusterization:

(and also I will scale YearsCode variable but not center to avoid getting NaNs because later I will logarithm it)

```{r message=FALSE, warning=FALSE}
set.seed(2020)
require(data.table); require(dplyr)
df <- fread("dataforproject2.csv", stringsAsFactors = T)
df <- df %>% select(Respondent, MainBranch, Employment, EdLevel, YearsCode)
# changing YearsCode to numeric
df <- subset(df, YearsCode != "Less than 1 year" & YearsCode != "More than 50 years")
# not centering to not achieve NaNs later in daisy() when log this variable
df$YearsCode <- scale(as.numeric(df$YearsCode), center = F, scale = T); df <- na.omit(df)
# creating less groups to get smaller matrix later
# for MainBranch
levels(df$MainBranch) <- c("Developer", "Student", "Partly-developer", "Hobbyist", "Ex-developer")
# for Employment
df$Employment <- df %>% 
  transmute(Employment = 
              fifelse(Employment == "Employed full-time", "Employed", "Partly or not employed"))
df$Employment <- as.factor(df$Employment)
# for Education
df$EdLevel <- df %>% 
  transmute(EdLevel = 
              fifelse(EdLevel == "I never completed any formal education" | 
                      EdLevel == "Primary/elementary school" | 
                      EdLevel == "Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)" |
                      EdLevel == "Professional degree (JD, MD, etc.)" | 
                      EdLevel == "Some college/university study without earning a degree", 
                  "Pre-degree", 
              fifelse(EdLevel == "Bachelorâ€™s degree (BA, BS, B.Eng., etc.)", 
                  "Bachelor degree", 
                  "Master of higher degree")))
df$EdLevel <- as.factor(df$EdLevel)
```


## Chosing variables

To clusterize R user meaningfully I take following variables:

  * **MainBranch**: *how close respondent to developing and programming* (but what about data analysis? - that's not developing, to highly depends on code-writing especially ML\NN linked jobs) 
  * **Employment**: *about job format, and I recoded it into two groups* 
  * **EdLevel**: *respondent's level of education, too recoded but into 3 groups* 
  * **YearsCode**: *scaled continuous variable about how many years respondent write code professionaly* 

With such variables I'm tryin to cluster respondents based on their level of coding experience and for that purpose I chose small but nice set of variables, described above.

## Exploring data

After preparing and recoding data (and choosing variables) there is need to describe structure of dataset:

```{r message=FALSE, warning=FALSE}
sapply(df[,c("MainBranch", "Employment", "EdLevel", "YearsCode")], summary)
```

  * **MainBranch**: the biggest group is developers, half-sized of that group is respondents who partly using code in their work, then about 630 respondents are students and lastly two groups about hundred respondents each consist hobbyist and ex-developers. *So there are huge amount of professional developers, more than half of the whole sample* 
  * **Employment**: nearly two thirds of a sample fully employed and other third partly of not employed
  * **EdLevel**: about half of the whole sample are ones with master degree or higher (PhD and so on), half-sized of that is group of bachelors and there is really small group of respondents without a degree
  * **YearsCode**: and that variable is centered and scaled, so there is nothing about it can be described now.

# Calculating distance

Firstly, I need to calculate distance before clustering anything and I choose *daisy()* function and *gower* distance metric because three variables are factors and only one is continuous, so there is need to chose algorithm and metric applicable for mixed data:

*(and also I delete respondents ids because such variable is meaningless in clusterization - but still I have it in my dataset, maybe I need it later)*

```{r message=FALSE, warning=FALSE}
library(ISLR); library(cluster)
gower_dist <- daisy(df[,-"Respondent"], metric = "gower", type = list(logratio = 4))
summary(gower_dist); gower_mat <- as.matrix(gower_dist)
```

Distance calculated and mean is on 0.5 - from that I can predict concentration of observation in the center and great variation and overlapping clusters, that is not good at all, but I still will try to test my set of variables.

## Most similar cases

```{r message=FALSE, warning=FALSE}
df[which(gower_mat == min(gower_mat[gower_mat != min(gower_mat)]), arr.ind = TRUE)[1, ], ]
```

Looks like identical twins, nice!

## Most dissimilar cases

```{r message=FALSE, warning=FALSE}
df[which(gower_mat == max(gower_mat[gower_mat != max(gower_mat)]), arr.ind = TRUE)[1, ], ]
```

So there is not or partly employed bachelor student vs. partly-coder with master of higher degree epmployee with great difference in years of coding professionally - works nice too, but I assumed there will be master developer vs. partly-remployed respondent without a degree.

## Dendrogram

```{r message=FALSE, warning=FALSE}
heatmap(gower_mat, symm = T,
        distfun = function(x) as.dist(x))
```

This is looks like too much clusters, more than 10, not really nice, but as I think it highly depends on data and there are some issues with it so I can't do anything.


# PAM

Firstly, I will clusterize data with PAM and describe my clusters:

```{r message=FALSE, warning=FALSE}
sil_width <- c(NA)

for(i in 2:10){
  pam_fit <- pam(gower_dist,
                 diss = TRUE,
                 k = i)
  sil_width[i] <- pam_fit$silinfo$avg.width
}

plot(1:10, sil_width,
     xlab = "Number of clusters", xaxt='n',
     ylab = "Silhouette Width",
     ylim = c(0,1))
axis(1, at = seq(2, 10, by = 1), las=2)
lines(1:10, sil_width)
```

I will choose **5 clusters** as optimal solution - more clusters can increase value but not so much and it will be hard to interpret that much clusters.

```{r message=FALSE, warning=FALSE}
pam_fit <- pam(gower_dist, diss = TRUE, k = 5)

pam_results <- df %>%
  mutate(cluster = pam_fit$clustering) %>%
  group_by(cluster) %>%
  do(the_summary = summary(.))
```

With medoids and plot I can describe clusters and their dissimilarities, but firtsly I will visualize my solution:


## Visualizing solution

```{r message=FALSE, warning=FALSE}
library(Rtsne); library(ggplot2)
tsne_obj <- Rtsne(gower_dist, is_distance = TRUE)

tsne_data <- tsne_obj$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit$clustering),
         name = df$Respondent)

ggplot(aes(x = X, y = Y), data = tsne_data) +
  geom_point(aes(color = cluster))
```

Looks awful, but I have three factor variables and only one numeric, so it's fine for such set of varibles and given data. Again, there is nothing can be said about clusters themselves by such plot, so it is better to describe clusters by summary:


## Describing clusters

```{r packages, message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
library(kableExtra)
```

```{r cluster1, echo=FALSE, message=FALSE, warning=FALSE}
kable(pam_results$the_summary[[1]], caption = "Cluster 1") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

**First** cluster mostly about employed partly-developers with bachelor degree and mean years of coding pro equals 0.8

```{r cluster2, echo=FALSE, message=FALSE, warning=FALSE}
kable(pam_results$the_summary[[2]], caption = "Cluster 2") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

**Second** cluster primarly about employed developers with master of higher degree and lesser years of coding pro equals to 0.7

```{r cluster3, echo=FALSE, message=FALSE, warning=FALSE}
kable(pam_results$the_summary[[3]], caption = "Cluster 3") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

**Third** cluster is about partly or not employed students who are still studying but have greater mean of years of coding pro equals 0.96

```{r cluster4, echo=FALSE, message=FALSE, warning=FALSE}
kable(pam_results$the_summary[[4]], caption = "Cluster 4") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

**Fourth** cluster is about partly-developers with jobs and master or higher degree and similar to second cluster mean of years coding pro

```{r cluster5, echo=FALSE, message=FALSE, warning=FALSE}
kable(pam_results$the_summary[[5]], caption = "Cluster 5") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

**Fifth** cluster, the last one, consists from employed developers with bachelor degree and greater mean of years of coding pro equals 0.9

```{r comparison, echo=FALSE, message=FALSE, warning=FALSE}
library(compareGroups)
df_clus <- df %>%
  mutate(cluster = pam_fit$clustering)
group <- compareGroups(cluster~., data = df_clus)
clustab <- createTable(group)
clustab
```

And maybe it will be more interesting to look at comparison table.

So there are nice clusters really separate from each other on all dimensions, I think that is fine solution.


# Other clustering method

(Source)[https://www.datanovia.com/en/blog/types-of-clustering-methods-overview-and-quick-start-r-code/]

```{r}
library(factoextra)
res.hc <- hclust(gower_dist, method = "ward.D2")

fviz_dend(res.hc, k = 5,
          cex = 0.5,
          color_labels_by_k = TRUE,
          rect = TRUE
          )
```

Looks nice and that's all for now!

But later I will try to explore this topic and understand more about different techniques, thank you for the course!

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(FactoMineR)
res.mca <- MFA(df[,-"Respondent"], group = c(), type = c("s","n","n","n"),
               graph=FALSE)

res.hcpc <- HCPC(res.mca, graph = FALSE, max = 3)
```

